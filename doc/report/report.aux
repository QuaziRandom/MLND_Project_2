\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Project Steps}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Classification vs Regression}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Dataset}{1}}
\newlabel{tab:data_characteristics}{{3}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Training and Evaluating Models}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Naive Bayes Classifier}{1}}
\citation{Metsis06}
\citation{Rish01}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:belief_bayesian_inference}{{1a}{2}}
\newlabel{sub@fig:belief_bayesian_inference}{{a}{2}}
\newlabel{fig:belief_naive_bayes}{{1b}{2}}
\newlabel{sub@fig:belief_naive_bayes}{{b}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example belief networks with some of the features of \texttt  {student-data}. \emph  {passed} is the classification variable indicating if a student will pass or not; \emph  {goout} indicates the time spent by a student going out with friends; \emph  {freetime} indicates the free time a student gets after school; and, \emph  {failures} indicates a student's failures in the past.\relax }}{2}}
\citation{boser1992}
\citation{boser1992}
\citation{joachims1998}
\citation{joachims2005}
\citation{hsu2003}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance of Naive Bayes Classifier (single run)\relax }}{3}}
\newlabel{tab:naive_bayes_1}{{1}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Performance of Naive Bayes Classifier (100 runs)\relax }}{3}}
\newlabel{tab:naive_bayes_100}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Support Vector Machine}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example Support Vector Machine based Classifier with an RBF kernel; \emph  {Failures} indicates a student's past failures; \emph  {Absences} indicates number of classes a student was absent for. Decision boundaries in grey (student passed) and white (student not passed) are underlying the data points of \emph  {passed} label from the dataset.\relax }}{4}}
\newlabel{fig:svc_rbf_example}{{2}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance of SVC Polynomial $2^{nd}$ degree Kernel (single run)\relax }}{4}}
\newlabel{tab:svc_poly_1}{{3}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Performance of SVC Polynomial $3^{rd}$ degree Kernel (single run)\relax }}{4}}
\newlabel{tab:svc_poly_3_degree_1}{{4}{4}}
\citation{hsu2003}
\citation{shapire1990}
\citation{Freund1997}
\citation{Schapire2013}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Performance of SVC Polynomial $2^{nd}$ degree Kernel (100 runs)\relax }}{5}}
\newlabel{tab:svc_poly_100}{{5}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Performance of SVC RBF Kernel (single run)\relax }}{5}}
\newlabel{tab:svc_rbf_1}{{6}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Performance of SVC RBF Kernel (100 runs)\relax }}{5}}
\newlabel{tab:svc_rbf_100}{{7}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Boosting}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Performance of AdaBoost Classifier (single run) with balanced dataset\relax }}{6}}
\newlabel{tab:adaboost_weak_balanced_1}{{8}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Performance of AdaBoost Classifier (100 runs) with balanced dataset\relax }}{6}}
\newlabel{tab:adaboost_weak_balanced_100}{{9}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Performance of AdaBoost Classifier (single run) with identical dataset as used for other models\relax }}{6}}
\newlabel{tab:adaboost_weak_unbalanced_1}{{10}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Performance of AdaBoost Classifier (100 runs) with identical dataset as used for other models\relax }}{6}}
\newlabel{tab:adaboost_weak_unbalanced_100}{{11}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Finding the Best Model}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Layman Explanation}{8}}
\newlabel{fig:possible_decision_boundaries}{{3a}{8}}
\newlabel{sub@fig:possible_decision_boundaries}{{a}{8}}
\newlabel{fig:optimal_decision_boundary}{{3b}{8}}
\newlabel{sub@fig:optimal_decision_boundary}{{b}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An example binary classification scheme with different decision boundaries\relax }}{8}}
\newlabel{fig:svm_decision_boundary_demo}{{3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces SVM based classifier that employs \emph  {kernel trick}. Courtesy: Alisneaky, \emph  {WikiMedia Commons}, 2011.\relax }}{9}}
\newlabel{fig:kernel_trick}{{4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Fine-tune and Performance of Best Model}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Notes}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Single run and 100 runs}{9}}
\newlabel{types_of_runs}{{6.1}{9}}
\citation{Olson2005}
\bibdata{report}
\bibcite{boser1992}{BGV92}
\bibcite{Freund1997}{FS97}
\bibcite{hsu2003}{HCL{$^{+}$}03}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}General Issues}{10}}
\newlabel{general_issues}{{6.2}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Degenerate Case}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Dataset balancing}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Indirect comparison}{10}}
\newlabel{indirect_comparison}{{6.2.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Neural Network}{10}}
\bibcite{joachims1998}{Joa98}
\bibcite{joachims2005}{Joa05}
\bibcite{Metsis06}{MAP06}
\bibcite{Olson2005}{Ols05}
\bibcite{Rish01}{Ris01}
\bibcite{shapire1990}{Sch90}
\bibcite{Schapire2013}{Sch13}
\bibstyle{alpha}
